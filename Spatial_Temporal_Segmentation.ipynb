{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6441e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "video = cv.VideoCapture(\"my_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46081f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video frame width: \t   854\n",
      "Video frame height: \t   480\n",
      "Video frame rate property: 23.976023976023978\n",
      "Video frame count: \t   136\n",
      "Video duration (s): \t   5.672333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display relative video propreties\n",
    "width = int(video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = video.get(cv.CAP_PROP_FPS)\n",
    "frame_count = int(video.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / frame_rate\n",
    "\n",
    "print(\"Video frame width: \\t  \", width)\n",
    "print(\"Video frame height: \\t  \", height)\n",
    "print(\"Video frame rate property:\", frame_rate)\n",
    "print(\"Video frame count: \\t  \", frame_count)\n",
    "print(\"Video duration (s): \\t  \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d91d9",
   "metadata": {},
   "source": [
    "2. Utilisez la fonction read pour extraire les frames de votre vidéo. Ensuite, sauvegardez les dans le dossier de travail à l’aide de la fonction imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407a9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 frames sauvegardées.\n"
     ]
    }
   ],
   "source": [
    "# Création du dossier pour stocker les frames\n",
    "if not os.path.exists('frames'):\n",
    "    os.makedirs('frames')\n",
    "\n",
    "frame_nb = 0\n",
    "frames_left = True\n",
    "\n",
    "while True:\n",
    "    frames_left, frame = video.read()\n",
    "    if not frames_left:\n",
    "        break\n",
    "\n",
    "    frame_name = os.path.join('frames', f\"frame_{frame_nb:04d}.jpg\")\n",
    "    cv.imwrite(frame_name, frame)  \n",
    "    frame_nb += 1\n",
    "\n",
    "print(f\"{frame_nb} frames sauvegardées.\")\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae4b16",
   "metadata": {},
   "source": [
    "question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41b2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.VideoCapture('my_video.mp4')\n",
    "frame_nb = 0\n",
    "\n",
    "while True:\n",
    "    frames_left, frame = video.read()\n",
    "    if not frames_left:\n",
    "        break\n",
    "    \n",
    "    cv.imshow('Frame', frame)  \n",
    "    frame_nb += 1\n",
    "    \n",
    "    # Attente de 50ms entre chaque frame\n",
    "    key = cv.waitKey(50)\n",
    "    \n",
    "    # S'arrêter avec la touche 'q'\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363b2fa",
   "metadata": {},
   "source": [
    "question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630c3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()  \n",
    "cv.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168fd66",
   "metadata": {},
   "source": [
    "convention en niveaux de gris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6384de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('grayscale_frames'):\n",
    "    os.makedirs('grayscale_frames')\n",
    "\n",
    "video = cv.VideoCapture('my_video.mp4')\n",
    "frame_nb = 0\n",
    "\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('grayscale_video.avi', fourcc, frame_rate, \n",
    "                     (width, height), isColor=False)\n",
    "\n",
    "while True:\n",
    "    frames_left, frame = video.read()\n",
    "    if not frames_left:\n",
    "        break\n",
    "    \n",
    "    # Conversion BGR vers niveaux de gris\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sauvegarde du frame en niveaux de gris\n",
    "    frame_name = os.path.join('grayscale_frames', f\"frame_{frame_nb:04d}.jpg\")\n",
    "    cv.imwrite(frame_name, gray)\n",
    "    \n",
    "    out.write(gray)\n",
    "    \n",
    "    cv.imshow('Frame Original', frame)\n",
    "    cv.imshow('Frame Niveaux de Gris', gray)\n",
    "    frame_nb += 1\n",
    "    \n",
    "    key = cv.waitKey(50)\n",
    "\n",
    "video.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe306ee6",
   "metadata": {},
   "source": [
    "Algorithme de seuillage globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Algorithme de Seuillage Global Heuristique ===\n",
      "\n",
      "Seuil initial T₀ = 15\n",
      "  Itération 1: T = 15.0000\n",
      "  Itération 2: T = 66.7674\n",
      "  Itération 3: T = 93.6191\n",
      "  Itération 4: T = 94.3681\n",
      "  Itération 5: T = 94.3909\n",
      "  Seuil final : T_final = 94.3909\n",
      "\n",
      "Seuil initial T₀ = 120\n",
      "  Itération 1: T = 120.0000\n",
      "  Itération 2: T = 95.0096\n",
      "  Itération 3: T = 94.4096\n",
      "  Itération 4: T = 94.3909\n",
      "  Itération 5: T = 94.3909\n",
      "  Seuil final : T_final = 94.3909\n",
      "\n",
      "Seuil initial T₀ = 240\n",
      "  Itération 1: T = 240.0000\n",
      "  Itération 2: T = 156.0672\n",
      "  Itération 3: T = 98.0923\n",
      "  Itération 4: T = 94.4791\n",
      "  Itération 5: T = 94.3909\n",
      "  Seuil final : T_final = 94.3909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frame = cv.imread('frames/frame_0089.jpg')\n",
    "gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Test avec différents seuils d'initialisation\n",
    "Thresholds = [15, 120, 240]\n",
    "\n",
    "for T_init in Thresholds:\n",
    "    print(f\"Seuil initial T₀ = {T_init}\")\n",
    "    T = T_init\n",
    "    \n",
    "    for iteration in range(5):\n",
    "        # Seuillage binaire\n",
    "        _, binary_frame = cv.threshold(gray_frame, T, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        # Calcul des moyennes des deux classes\n",
    "        mean1 = gray_frame[binary_frame == 255].mean()  # Pixels blancs (> T)\n",
    "        mean2 = gray_frame[binary_frame == 0].mean()     # Pixels noirs (≤ T)\n",
    "        \n",
    "        # Nouveau seuil\n",
    "        T_new = (mean1 + mean2) / 2\n",
    "        \n",
    "        print(f\"  Itération {iteration+1}: T = {T:.4f}\")\n",
    "        \n",
    "        # Affichage optionnel\n",
    "        # cv.imshow('Binary Frame', binary_frame)\n",
    "        # cv.waitKey(500)\n",
    "        \n",
    "        T = T_new\n",
    "    \n",
    "    print(f\"  Seuil final : T_final = {T:.4f}\\n\")\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135ce01",
   "metadata": {},
   "source": [
    "Methode d'otsu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c1b9f",
   "metadata": {},
   "source": [
    "code d'implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473b5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur un seul frame\n",
    "frame = cv.imread('frames/frame_0089.jpg')\n",
    "gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Seuillage d'Otsu\n",
    "_, binary_frame = cv.threshold(gray_frame, 0, 255, \n",
    "                               cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "cv.imshow('Frame Original (Niveaux de Gris)', gray_frame)\n",
    "cv.imshow('Segmentation Otsu', binary_frame)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e18e0",
   "metadata": {},
   "source": [
    "Application sur toute la video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c4916",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "video = cv.VideoCapture('my_video.mp4')\n",
    "\n",
    "while True:\n",
    "    frames_left, frame = video.read()\n",
    "    if not frames_left:\n",
    "        break\n",
    "    \n",
    "    # Conversion en niveaux de gris\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Segmentation d'Otsu\n",
    "    _, binary_frame = cv.threshold(gray_frame, 0, 255, \n",
    "                                   cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    \n",
    "    cv.imshow('Vidéo Originale', frame)\n",
    "    cv.imshow('Vidéo Segmentée (Otsu)', binary_frame)\n",
    "    \n",
    "    key = cv.waitKey(50) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8a937",
   "metadata": {},
   "source": [
    "Segmentation temporelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295180e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "video = cv.VideoCapture('grayscale_video.avi')\n",
    "lambda_val = 94.4258  # Seuil pour binariser la différence\n",
    "frames_left, old_frame = video.read()\n",
    "\n",
    "while True:\n",
    "    frames_left, frame = video.read()\n",
    "    if not frames_left:\n",
    "        break\n",
    "    # Calcul de la différence absolue\n",
    "    difference = cv.absdiff(old_frame, frame)\n",
    "    # Seuillage de la différence\n",
    "    _, difference_binary = cv.threshold(difference, lambda_val, 255, \n",
    "                                        cv.THRESH_BINARY)\n",
    "    cv.imshow('Frame Courant', frame)\n",
    "    cv.imshow('Différence (Mouvement Détecté)', difference_binary)\n",
    "    \n",
    "\n",
    "    old_frame = frame\n",
    "    \n",
    "    key = cv.waitKey(50) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2633e",
   "metadata": {},
   "source": [
    "Differentiation de 3 frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c718443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegardé : N=5 (frame 90)\n",
      "Sauvegardé : N=12 (frame 90)\n",
      "Sauvegardé : N=23 (frame 90)\n",
      "Sauvegardé : N=30 (frame 90)\n",
      "Sauvegardé : N=40 (frame 90)\n",
      "Sauvegardé : N=45 (frame 90)\n",
      "Terminé ! Vérifiez le dossier 'comparaison_N/'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = 'grayscale_frames'\n",
    "grayscale_frames = sorted(os.listdir(folder))\n",
    "lambda_val = 94.4258\n",
    "\n",
    "# Créer un dossier pour sauvegarder les résultats\n",
    "os.makedirs('comparaison_N', exist_ok=True)\n",
    "\n",
    "# Frame de référence pour comparaison\n",
    "frame_ref = 90\n",
    "\n",
    "N_values = [5, 12, 23, 30, 40 , 45]\n",
    "\n",
    "for N in N_values:\n",
    "    i = frame_ref\n",
    "    \n",
    "    # Vérification des bornes\n",
    "    if i - N < 0 or i + N >= len(grayscale_frames):\n",
    "        print(f\"N={N} : Impossible (hors limites)\")\n",
    "        continue\n",
    "    \n",
    "    # Chargement des trois frames\n",
    "    img = cv.imread(os.path.join(folder, grayscale_frames[i]), cv.IMREAD_GRAYSCALE)\n",
    "    img_after = cv.imread(os.path.join(folder, grayscale_frames[i + N]), cv.IMREAD_GRAYSCALE)\n",
    "    img_before = cv.imread(os.path.join(folder, grayscale_frames[i - N]), cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Calcul des différences\n",
    "    diff1 = cv.absdiff(img_after, img)\n",
    "    _, diff1 = cv.threshold(diff1, lambda_val, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    diff2 = cv.absdiff(img, img_before)\n",
    "    _, diff2 = cv.threshold(diff2, lambda_val, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    # Intersection\n",
    "    result = cv.bitwise_and(diff1, diff2)\n",
    "    \n",
    "    # SAUVEGARDE des résultats\n",
    "    cv.imwrite(f'comparaison_N/N_{N}_detection.jpg', result)\n",
    "    cv.imwrite(f'comparaison_N/N_{N}_original.jpg', img)\n",
    "    \n",
    "    print(f\"Sauvegardé : N={N} (frame {frame_ref})\")\n",
    "\n",
    "print(\"Terminé ! Vérifiez le dossier 'comparaison_N/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4438527",
   "metadata": {},
   "source": [
    "Adaptive background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460a01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test avec α = 0.01 ===\n",
      "Traité 135 frames avec α=0.01\n",
      "\n",
      "=== Test avec α = 0.05 ===\n",
      "Traité 135 frames avec α=0.05\n",
      "\n",
      "=== Test avec α = 0.1 ===\n",
      "Traité 135 frames avec α=0.1\n",
      "\n",
      "=== Test avec α = 0.5 ===\n",
      "Traité 135 frames avec α=0.5\n",
      "\n",
      "=== Test avec α = 0.9 ===\n",
      "Traité 135 frames avec α=0.9\n",
      "\n",
      "=== Test avec α = 0.96 ===\n",
      "Traité 135 frames avec α=0.96\n",
      "\n",
      "=== Test avec α = 0.99 ===\n",
      "Traité 135 frames avec α=0.99\n"
     ]
    }
   ],
   "source": [
    "video = cv.VideoCapture('my_video.mp4')\n",
    "lambda_val = 94.4258\n",
    "frame_rate = video.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "# TESTER différentes valeurs de α\n",
    "alpha_values = [0.01, 0.05, 0.1, 0.5, 0.9, 0.96, 0.99]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"\\n=== Test avec α = {alpha} ===\")\n",
    "    \n",
    "    # Réinitialiser la vidéo\n",
    "    video.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    frames_left, background = video.read()\n",
    "    background = cv.cvtColor(background, cv.COLOR_BGR2GRAY).astype(float)\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        frames_left, frame = video.read()\n",
    "        if not frames_left:\n",
    "            break\n",
    "        \n",
    "        gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY).astype(float)\n",
    "        \n",
    "        # Différence avec arrière-plan\n",
    "        diff = cv.absdiff(gray_frame, background)\n",
    "        _, diff_binary = cv.threshold(diff.astype('uint8'), lambda_val, 255, \n",
    "                                      cv.THRESH_BINARY)\n",
    "        \n",
    "        # Mise à jour arrière-plan\n",
    "        background = alpha * gray_frame + (1 - alpha) * background\n",
    "        \n",
    "        # Affichage\n",
    "        cv.imshow(f'α={alpha} - Détection', diff_binary)\n",
    "        cv.imshow(f'α={alpha} - Background', background.astype('uint8'))\n",
    "        cv.imshow('Frame Original', frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        key = cv.waitKey(50) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv.destroyAllWindows()\n",
    "    print(f\"Traité {frame_count} frames avec α={alpha}\")\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe3d18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegardé: alpha_0.01.jpg\n",
      "Sauvegardé: alpha_0.10.jpg\n",
      "Sauvegardé: alpha_0.96.jpg\n",
      "Sauvegardé: alpha_0.99.jpg\n",
      "\n",
      "Ouvrez les images dans 'alpha_comparison/' pour voir les différences !\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.makedirs('alpha_comparison', exist_ok=True)\n",
    "\n",
    "video_path = 'my_video.mp4'\n",
    "lambda_val = 94.4258\n",
    "alpha_values = [0.01, 0.1, 0.96, 0.99]\n",
    "frame_to_capture = 100  # Frame de référence\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    video = cv.VideoCapture(video_path)\n",
    "    \n",
    "    _, background = video.read()\n",
    "    background = cv.cvtColor(background, cv.COLOR_BGR2GRAY).astype(float)\n",
    "    \n",
    "    for i in range(frame_to_capture + 1):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY).astype(float)\n",
    "        \n",
    "        diff = cv.absdiff(gray_frame, background)\n",
    "        _, diff_binary = cv.threshold(diff.astype('uint8'), lambda_val, 255, \n",
    "                                      cv.THRESH_BINARY)\n",
    "        \n",
    "        background = alpha * gray_frame + (1 - alpha) * background\n",
    "        \n",
    "        # Sauvegarder à la frame cible\n",
    "        if i == frame_to_capture:\n",
    "            combined = np.hstack([\n",
    "                gray_frame.astype('uint8'),\n",
    "                diff_binary,\n",
    "                background.astype('uint8')\n",
    "            ])\n",
    "            \n",
    "            cv.putText(combined, f'alpha={alpha}', (10, 30), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            \n",
    "            cv.imwrite(f'alpha_comparison/alpha_{alpha:.2f}.jpg', combined)\n",
    "            print(f\"Sauvegardé: alpha_{alpha:.2f}.jpg\")\n",
    "    \n",
    "    video.release()\n",
    "\n",
    "print(\"\\nOuvrez les images dans 'alpha_comparison/' pour voir les différences !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc819336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appuyez sur 'q' pour quitter\n",
      "Fin de la vidéo\n",
      "Terminé!\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "video_path = 'my_video.mp4'\n",
    "lambda_val = 94.4258\n",
    "\n",
    "# Valeurs de α à tester\n",
    "alpha_values = [0.01, 0.05, 0.1, 0.2, 0.5, 0.96]\n",
    "\n",
    "# Ouvrir une vidéo pour chaque α\n",
    "videos = [cv.VideoCapture(video_path) for _ in alpha_values]\n",
    "backgrounds = []\n",
    "\n",
    "# Initialisation des backgrounds\n",
    "for video in videos:\n",
    "    _, bg = video.read()\n",
    "    backgrounds.append(cv.cvtColor(bg, cv.COLOR_BGR2GRAY).astype(float))\n",
    "\n",
    "print(\"Appuyez sur 'q' pour quitter\")\n",
    "\n",
    "while True:\n",
    "    rows = []\n",
    "    all_frames_read = True\n",
    "    \n",
    "    for i, (video, alpha) in enumerate(zip(videos, alpha_values)):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            all_frames_read = False\n",
    "            break\n",
    "        \n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY).astype(float)\n",
    "        \n",
    "        # Calcul de la différence\n",
    "        diff = cv.absdiff(gray, backgrounds[i])\n",
    "        _, binary = cv.threshold(diff.astype('uint8'), lambda_val, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        # Mise à jour du background\n",
    "        backgrounds[i] = alpha * gray + (1 - alpha) * backgrounds[i]\n",
    "        \n",
    "        # Compter pixels de mouvement\n",
    "        motion_pixels = np.sum(binary > 0)\n",
    "        \n",
    "        # Créer une ligne avec les 3 images côte à côte\n",
    "        row = np.hstack([\n",
    "            gray.astype('uint8'),\n",
    "            binary,\n",
    "            backgrounds[i].astype('uint8')\n",
    "        ])\n",
    "        \n",
    "        # Ajouter les labels et statistiques\n",
    "        cv.putText(row, f'alpha={alpha}', (10, 30), \n",
    "                  cv.FONT_HERSHEY_SIMPLEX, 0.7, (255), 2)\n",
    "        cv.putText(row, f'{motion_pixels} px', (10, 60), \n",
    "                  cv.FONT_HERSHEY_SIMPLEX, 0.5, (255), 1)\n",
    "        \n",
    "        # Ajouter labels des colonnes (seulement pour la première ligne)\n",
    "        if i == 0:\n",
    "            cv.putText(row, 'FRAME', (gray.shape[1]//2 - 50, row.shape[0] - 10), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 0.5, (200), 1)\n",
    "            cv.putText(row, 'DETECTION', (gray.shape[1] + gray.shape[1]//2 - 70, row.shape[0] - 10), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 0.5, (200), 1)\n",
    "            cv.putText(row, 'BACKGROUND', (2*gray.shape[1] + gray.shape[1]//2 - 80, row.shape[0] - 10), \n",
    "                      cv.FONT_HERSHEY_SIMPLEX, 0.5, (200), 1)\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    if not all_frames_read or len(rows) < len(alpha_values):\n",
    "        print(\"Fin de la vidéo\")\n",
    "        break\n",
    "    \n",
    "    # Empiler toutes les lignes verticalement\n",
    "    grid = np.vstack(rows)\n",
    "    \n",
    "    # Ajouter un titre général\n",
    "    title_bar = np.zeros((50, grid.shape[1]), dtype=np.uint8)\n",
    "    cv.putText(title_bar, 'Comparaison des valeurs de alpha', \n",
    "              (grid.shape[1]//2 - 200, 35), cv.FONT_HERSHEY_SIMPLEX, 1, (255), 2)\n",
    "    \n",
    "    final_display = np.vstack([title_bar, grid])\n",
    "    \n",
    "    cv.imshow('Comparaison Alpha - Adaptive Background Subtraction', final_display)\n",
    "    \n",
    "    key = cv.waitKey(50) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libération\n",
    "for video in videos:\n",
    "    video.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "\n",
    "print(\"Terminé!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cb47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mémoire : -229 frames = -9.5 secondes\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "# Temps pour qu'un pixel \"oublie\" 90% de son influence\n",
    "n = -np.log(0.1) / np.log(1 - alpha)\n",
    "print(f\"Mémoire : {n:.0f} frames = {n/24:.1f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd48e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α=0.005 | Avg: 3998 px | Std: 3486 px | Score: 1.15\n",
      "α=0.010 | Avg: 3836 px | Std: 3384 px | Score: 1.13\n",
      "α=0.020 | Avg: 2900 px | Std: 2845 px | Score: 1.02\n",
      "α=0.030 | Avg: 2458 px | Std: 2309 px | Score: 1.06\n",
      "α=0.050 | Avg: 1915 px | Std: 1852 px | Score: 1.03\n",
      "α=0.100 | Avg: 1170 px | Std: 1170 px | Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "video = cv.VideoCapture('my_video.mp4')\n",
    "lambda_val = 94.4258\n",
    "\n",
    "alphas = [0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "\n",
    "for alpha in alphas:\n",
    "    video.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    _, bg = video.read()\n",
    "    background = cv.cvtColor(bg, cv.COLOR_BGR2GRAY).astype(float)\n",
    "    \n",
    "    motion_pixels_list = []\n",
    "    \n",
    "    for i in range(200):  # 200 frames\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY).astype(float)\n",
    "        diff = cv.absdiff(gray, background)\n",
    "        _, binary = cv.threshold(diff.astype('uint8'), lambda_val, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        motion_pixels = np.sum(binary > 0)\n",
    "        motion_pixels_list.append(motion_pixels)\n",
    "        \n",
    "        background = alpha * gray + (1 - alpha) * background\n",
    "    \n",
    "    avg = np.mean(motion_pixels_list)\n",
    "    std = np.std(motion_pixels_list)\n",
    "    \n",
    "    print(f\"α={alpha:.3f} | Avg: {avg:.0f} px | Std: {std:.0f} px | Score: {avg/std:.2f}\")\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2662b12c",
   "metadata": {},
   "source": [
    "MOG2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025434dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traité 136 frames avec MOG2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture('my_video.mp4')\n",
    "\n",
    "# Création du soustracteur MOG2\n",
    "backSub_mog2 = cv.createBackgroundSubtractorMOG2(\n",
    "    history=500,           # Historique de 500 frames\n",
    "    varThreshold=16,       # Seuil de variance\n",
    "    detectShadows=True     # Détection des ombres activée\n",
    ")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Application du soustracteur MOG2\n",
    "    fg_mask = backSub_mog2.apply(frame)\n",
    "    \n",
    "    # Affichage\n",
    "    cv.imshow('Frame Original', frame)\n",
    "    cv.imshow('MOG2 - Detection', fg_mask)\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    key = cv.waitKey(50) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "\n",
    "print(f\"Traité {frame_count} frames avec MOG2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae1909",
   "metadata": {},
   "source": [
    "KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08166f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traité 136 frames avec KNN\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture('my_video.mp4')\n",
    "\n",
    "# Création du soustracteur KNN\n",
    "backSub_knn = cv.createBackgroundSubtractorKNN(\n",
    "    history=500,\n",
    "    dist2Threshold=400.0,\n",
    "    detectShadows=True\n",
    ")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Application du soustracteur KNN\n",
    "    fg_mask = backSub_knn.apply(frame)\n",
    "    \n",
    "    # Affichage\n",
    "    cv.imshow('Frame Original', frame)\n",
    "    cv.imshow('KNN - Detection', fg_mask)\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    key = cv.waitKey(50) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "\n",
    "print(f\"Traité {frame_count} frames avec KNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
